{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ce58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2e6cd5e",
   "metadata": {},
   "source": [
    "## Prepare QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b29650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "import json\n",
    "def prepare_qa(file_path: str):\n",
    "    \"\"\"\n",
    "    Prepares QA pairs from a JSONL file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:  # Specify UTF-8 encoding\n",
    "        data = [json.loads(line) for line in file]\n",
    "\n",
    "    qa = []\n",
    "    for item in data:\n",
    "        qa.append({'question': item['question'], 'options': item['options'], 'answer': item['answer_idx']})\n",
    "    \n",
    "    return qa\n",
    "\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "516c8c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA = prepare_qa(r\"E:\\Git_clone\\RAG\\qa_dataset\\data_clean\\questions\\US\\4_options\\phrases_no_exclude_test.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088fb375",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02aafd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chatbot, importlib\n",
    "importlib.reload(chatbot)\n",
    "from chatbot import Chatbot\n",
    "chatbot = Chatbot(\"mistral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984f987f",
   "metadata": {},
   "source": [
    "### Vector retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b2bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectordb import create_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c3fc683",
   "metadata": {},
   "outputs": [],
   "source": [
    "vretriever = create_retriever(r\"/workspaces/YuE/faiss_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8439f1db",
   "metadata": {},
   "source": [
    "### Graph retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf3c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphdb import gretriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2f458db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, rag_type = None, k = 5):\n",
    "    if rag_type == None:\n",
    "        return \"\"\n",
    "    elif rag_type == \"rag\":\n",
    "        contexts = vretriever.get_relevant_documents(query, k=k)\n",
    "        return \"\\n\\n\".join([context.page_content for context in contexts])\n",
    "    elif rag_type == \"grag\":\n",
    "        contexts = vretriever.get_relevant_documents(query, k=k)\n",
    "        contexts = gretriever(\"\\n\".join([context.page_content for context in contexts]), extract_model=\"mistral\")\n",
    "        return \"\\n\".join([context for context in contexts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50c47a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_qa(qa, rag_type = None, k = 5):\n",
    "    context = retrieve(qa['question'], rag_type, k=k)\n",
    "    prompt = f\"\"\"\n",
    "    You are a medical expert. Answer the question by coorperate the provided context with your knowledgement.\n",
    "    Document: {context}\n",
    "    Question: {qa['question']}\n",
    "    Options:\n",
    "    A: {qa['options']['A']}\n",
    "    B: {qa['options']['B']}\n",
    "    C: {qa['options']['C']}\n",
    "    D: {qa['options']['D']}\n",
    "    Answer: (Only return A:, B:, C:, or D: without any explanation or other text. Do not include the context or the question in your answer.) \n",
    "    \"\"\"\n",
    "    response = chatbot.chat(prompt)\n",
    "    # print(\"Prompt: \", prompt, '\\n')\n",
    "    if \"A:\" in response:\n",
    "        answer = \"A\"\n",
    "    elif \"B:\" in response:\n",
    "        answer = \"B\"\n",
    "    elif \"C:\" in response:\n",
    "        answer = \"C\"\n",
    "    elif \"D:\" in response:\n",
    "        answer = \"D\"\n",
    "    else:\n",
    "        answer = None\n",
    "\n",
    "    # print(response,\" \", answer, \"  \", qa['answer'])\n",
    "    return answer == qa['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "980a82f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def process_qa_with_retry(qa, rag_type=None, retries=8, delay=1):\n",
    "    \"\"\"\n",
    "    Processes a single QA pair with retry logic for rate-limiting errors.\n",
    "\n",
    "    Parameters:\n",
    "        qa (dict): A single QA pair to process.\n",
    "        rag_type (str): Type of retriever to use (e.g., \"rag\", \"grag\").\n",
    "        retries (int): Number of retries for rate-limiting errors.\n",
    "        delay (int): Delay in seconds between retries.\n",
    "\n",
    "    Returns:\n",
    "        bool: Whether the processed answer matches the expected answer.\n",
    "    \"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            return process_qa(qa, rag_type)\n",
    "        except Exception as e:\n",
    "            if \"rate limit\" in str(e).lower():\n",
    "                # print(f\"Rate limit encountered. Retrying in {delay} seconds... (Attempt {attempt + 1}/{retries})\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                print(f\"Error processing QA: {e}\")\n",
    "                break\n",
    "    return False  # Return False if all retries fail\n",
    "\n",
    "def process_qa_parallel(QA, n_workers=4, rag_type=None, k=5):\n",
    "    \"\"\"\n",
    "    Processes QA pairs in parallel and calculates accuracy.\n",
    "\n",
    "    Parameters:\n",
    "        QA (list): List of QA pairs to process.\n",
    "        n_workers (int): Number of worker threads to use.\n",
    "        rag_type (str): Type of retriever to use (e.g., \"rag\", \"grag\").\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy of the processed QA pairs.\n",
    "    \"\"\"\n",
    "    with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "        # Use tqdm for progress tracking\n",
    "        results = list(tqdm(\n",
    "            executor.map(lambda qa: process_qa_with_retry(qa, rag_type, k), QA),\n",
    "            total=len(QA),\n",
    "            desc=\"Processing QA\"\n",
    "        ))\n",
    "\n",
    "    # Calculate and return accuracy\n",
    "    total_correct = sum(results)\n",
    "    accuracy = total_correct / len(QA)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "003b43a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_qa_parallel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_qa_parallel\u001b[49m(QA, n_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, rag_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrag\u001b[39m\u001b[38;5;124m\"\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'process_qa_parallel' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy = process_qa_parallel(QA, n_workers=1, rag_type=\"grag\", k=8)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f003c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7250589159465829"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
